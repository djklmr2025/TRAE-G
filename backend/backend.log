INFO:     Will watch for changes in these directories: ['C:\\arkaios\\arkaios-neural-agent-1\\backend']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [16504] using StatReload
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
USER_AGENT environment variable not set, consider setting it to identify your requests.
Process SpawnProcess-1:
Traceback (most recent call last):
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\multiprocessing\process.py", line 314, in _bootstrap
    self.run()
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\multiprocessing\process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\server.py", line 67, in run
    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\_compat.py", line 60, in asyncio_run
    return loop.run_until_complete(main)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 646, in run_until_complete
    return future.result()
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\server.py", line 71, in serve
    await self._serve(sockets)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\server.py", line 78, in _serve
    config.load()
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\config.py", line 439, in load
    self.loaded_app = import_from_string(self.app)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "C:\arkaios\arkaios-neural-agent-1\backend\main.py", line 6, in <module>
    from routers.aiagent.generic import router as aiagent_router
  File "C:\arkaios\arkaios-neural-agent-1\backend\routers\aiagent\generic.py", line 19, in <module>
    from utils.agentic_tools import run_tool_server_side
  File "C:\arkaios\arkaios-neural-agent-1\backend\utils\agentic_tools.py", line 8, in <module>
    llm = get_llm("suggestor", temperature=0.3)
  File "C:\arkaios\arkaios-neural-agent-1\backend\utils\llm_provider.py", line 112, in get_llm
    raise ValueError(f"Unsupported model type '{model_type}' for agent '{agent}'")
ValueError: Unsupported model type 'openai|azure_openai|anthropic|bedrock|gemini' for agent 'suggestor'
WARNING:  StatReload detected changes in 'utils\llm_provider.py'. Reloading...
 None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
USER_AGENT environment variable not set, consider setting it to identify your requests.
Process SpawnProcess-2:
Traceback (most recent call last):
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\multiprocessing\process.py", line 314, in _bootstrap
    self.run()
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\multiprocessing\process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\server.py", line 67, in run
    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\_compat.py", line 60, in asyncio_run
    return loop.run_until_complete(main)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 646, in run_until_complete
    return future.result()
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\server.py", line 71, in serve
    await self._serve(sockets)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\server.py", line 78, in _serve
    config.load()
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\config.py", line 439, in load
    self.loaded_app = import_from_string(self.app)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "C:\arkaios\arkaios-neural-agent-1\backend\main.py", line 6, in <module>
    from routers.aiagent.generic import router as aiagent_router
  File "C:\arkaios\arkaios-neural-agent-1\backend\routers\aiagent\generic.py", line 19, in <module>
    from utils.agentic_tools import run_tool_server_side
  File "C:\arkaios\arkaios-neural-agent-1\backend\utils\agentic_tools.py", line 8, in <module>
    llm = get_llm("suggestor", temperature=0.3)
  File "C:\arkaios\arkaios-neural-agent-1\backend\utils\llm_provider.py", line 113, in get_llm
    raise ValueError(f"Unsupported model type '{model_type}' for agent '{agent}'")
ValueError: Unsupported model type 'openai|azure_openai|anthropic|bedrock|gemini' for agent 'suggestor'
DEBUG: agent=suggestor, model_type='openai|azure_openai|anthropic|bedrock|gemini'
WARNING:  StatReload detected changes in 'fix_env_models.py'. Reloading...
 None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
USER_AGENT environment variable not set, consider setting it to identify your requests.
Process SpawnProcess-3:
Traceback (most recent call last):
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\multiprocessing\process.py", line 314, in _bootstrap
    self.run()
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\multiprocessing\process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\server.py", line 67, in run
    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\_compat.py", line 60, in asyncio_run
    return loop.run_until_complete(main)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\asyncio\base_events.py", line 646, in run_until_complete
    return future.result()
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\server.py", line 71, in serve
    await self._serve(sockets)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\server.py", line 78, in _serve
    config.load()
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\config.py", line 439, in load
    self.loaded_app = import_from_string(self.app)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\site-packages\uvicorn\importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
  File "C:\Users\djklm\AppData\Local\Programs\Python\Python310\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "C:\arkaios\arkaios-neural-agent-1\backend\main.py", line 6, in <module>
    from routers.aiagent.generic import router as aiagent_router
  File "C:\arkaios\arkaios-neural-agent-1\backend\routers\aiagent\generic.py", line 19, in <module>
    from utils.agentic_tools import run_tool_server_side
  File "C:\arkaios\arkaios-neural-agent-1\backend\utils\agentic_tools.py", line 8, in <module>
    llm = get_llm("suggestor", temperature=0.3)
  File "C:\arkaios\arkaios-neural-agent-1\backend\utils\llm_provider.py", line 113, in get_llm
    raise ValueError(f"Unsupported model type '{model_type}' for agent '{agent}'")
ValueError: Unsupported model type 'openai|azure_openai|anthropic|bedrock|gemini' for agent 'suggestor'
DEBUG: agent=suggestor, model_type='openai|azure_openai|anthropic|bedrock|gemini'
